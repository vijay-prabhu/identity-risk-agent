{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: GenAI Agent (RAG + LangGraph)\n",
    "\n",
    "This notebook demonstrates the GenAI agent capabilities:\n",
    "- Vector store for semantic search\n",
    "- RAG pipeline for context-aware explanations\n",
    "- LangGraph agent for autonomous risk analysis\n",
    "- MCP-like tools for agent actions\n",
    "- Privacy controls (PII detection/redaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vector Store for Semantic Search\n",
    "\n",
    "The vector store uses Qdrant and sentence-transformers to enable semantic search over login events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.vector_store import IdentityVectorStore, create_event_text\n",
    "\n",
    "# Create in-memory vector store\n",
    "vector_store = IdentityVectorStore()\n",
    "print(f\"Embedding dimension: {vector_store.embedding_dim}\")\n",
    "print(f\"Model: {vector_store.embedding_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sample events\n",
    "sample_events = [\n",
    "    {\n",
    "        \"event_id\": \"evt_001\",\n",
    "        \"text\": \"Normal login from known device in San Francisco during business hours\",\n",
    "        \"user_id\": \"employee_001\",\n",
    "        \"risk_score\": 0.1,\n",
    "    },\n",
    "    {\n",
    "        \"event_id\": \"evt_002\",\n",
    "        \"text\": \"Suspicious login from unknown device in Russia with VPN, no MFA\",\n",
    "        \"user_id\": \"user_002\",\n",
    "        \"risk_score\": 0.95,\n",
    "    },\n",
    "    {\n",
    "        \"event_id\": \"evt_003\",\n",
    "        \"text\": \"Login from new mobile device at unusual hour (3am) but with MFA\",\n",
    "        \"user_id\": \"employee_003\",\n",
    "        \"risk_score\": 0.4,\n",
    "    },\n",
    "    {\n",
    "        \"event_id\": \"evt_004\",\n",
    "        \"text\": \"Multiple failed login attempts followed by successful login with VPN\",\n",
    "        \"user_id\": \"user_004\",\n",
    "        \"risk_score\": 0.75,\n",
    "    },\n",
    "]\n",
    "\n",
    "vector_store.add_events_batch(sample_events, tenant_id=\"demo\")\n",
    "print(f\"Added {len(sample_events)} events to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic search\n",
    "results = vector_store.search(\n",
    "    query=\"suspicious VPN login from unknown device\",\n",
    "    tenant_id=\"demo\",\n",
    "    limit=3,\n",
    ")\n",
    "\n",
    "print(\"Search results for 'suspicious VPN login from unknown device':\")\n",
    "for r in results:\n",
    "    print(f\"  Score: {r['score']:.3f} | {r['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Pipeline for Explanations\n",
    "\n",
    "The RAG pipeline combines vector search with LLM generation (or template fallback) to explain risk decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.rag import RAGPipeline\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "rag = RAGPipeline()\n",
    "\n",
    "# Ingest historical events\n",
    "historical_events = [\n",
    "    {\n",
    "        \"event_id\": \"hist_001\",\n",
    "        \"user_id\": \"attacker_001\",\n",
    "        \"device_id\": \"device_unknown_abc\",\n",
    "        \"location_country\": \"RU\",\n",
    "        \"mfa_used\": False,\n",
    "        \"vpn_detected\": True,\n",
    "        \"success\": False,\n",
    "        \"risk_score\": 0.92,\n",
    "    },\n",
    "    {\n",
    "        \"event_id\": \"hist_002\",\n",
    "        \"user_id\": \"employee_002\",\n",
    "        \"device_id\": \"laptop_002\",\n",
    "        \"location_country\": \"US\",\n",
    "        \"mfa_used\": True,\n",
    "        \"vpn_detected\": False,\n",
    "        \"success\": True,\n",
    "        \"risk_score\": 0.1,\n",
    "    },\n",
    "]\n",
    "\n",
    "count = rag.ingest_events(historical_events, tenant_id=\"demo\")\n",
    "print(f\"Ingested {count} historical events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get explanation for a suspicious event\n",
    "explanation_result = rag.query(\n",
    "    query=\"Why was this login flagged as high risk?\",\n",
    "    event={\n",
    "        \"user_id\": \"suspicious_user\",\n",
    "        \"device_id\": \"device_unknown_xyz\",\n",
    "        \"ip\": \"185.199.1.100\",\n",
    "        \"location_country\": \"CN\",\n",
    "        \"mfa_used\": False,\n",
    "        \"vpn_detected\": True,\n",
    "    },\n",
    "    risk_score=0.85,\n",
    "    risk_level=\"high\",\n",
    "    risk_factors=[\"Unknown device\", \"VPN detected\", \"No MFA\", \"High-risk location\"],\n",
    "    tenant_id=\"demo\",\n",
    ")\n",
    "\n",
    "print(\"Risk Explanation:\")\n",
    "print(\"=\" * 50)\n",
    "print(explanation_result[\"explanation\"])\n",
    "print(f\"\\nSimilar events found: {explanation_result['similar_events']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LangGraph Agent\n",
    "\n",
    "The LangGraph agent autonomously investigates login events and recommends actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.agent import run_risk_agent, IdentityTools\n",
    "\n",
    "# Test the agent with a normal login\n",
    "print(\"=== Normal Login Analysis ===\")\n",
    "result = run_risk_agent(\n",
    "    user_id=\"employee_001\",\n",
    "    device_id=\"laptop_001\",\n",
    "    ip=\"10.0.0.1\",\n",
    "    mfa_used=True,\n",
    "    vpn_detected=False,\n",
    ")\n",
    "\n",
    "print(f\"Risk Score: {result['risk_score']:.2f}\")\n",
    "print(f\"Risk Level: {result['risk_level']}\")\n",
    "print(f\"Recommended Action: {result['recommended_action']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a suspicious login\n",
    "print(\"=== Suspicious Login Analysis ===\")\n",
    "result = run_risk_agent(\n",
    "    user_id=\"unknown_user_999\",\n",
    "    device_id=\"device_unknown_xyz\",\n",
    "    ip=\"185.199.1.100\",\n",
    "    mfa_used=False,\n",
    "    vpn_detected=True,\n",
    ")\n",
    "\n",
    "print(f\"Risk Score: {result['risk_score']:.2f}\")\n",
    "print(f\"Risk Level: {result['risk_level']}\")\n",
    "print(f\"Recommended Action: {result['recommended_action']}\")\n",
    "print(f\"\\nInvestigation Notes:\")\n",
    "for note in result['investigation_notes']:\n",
    "    print(f\"  - {note}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCP-like Tools\n",
    "\n",
    "The agent uses MCP-like tools with Pydantic schemas for structured input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.risk_score import RiskScoreInput, execute as score_execute, TOOL_SCHEMA as risk_schema\n",
    "from src.tools.user_history import UserHistoryInput, execute as history_execute, TOOL_SCHEMA as history_schema\n",
    "from src.tools.quarantine import QuarantineInput, execute as quarantine_execute, TOOL_SCHEMA as quarantine_schema\n",
    "\n",
    "# Show tool schemas\n",
    "print(\"Available Tools:\")\n",
    "for schema in [risk_schema, history_schema, quarantine_schema]:\n",
    "    print(f\"  - {schema['name']}: {schema['description'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use risk score tool\n",
    "risk_input = RiskScoreInput(\n",
    "    user_id=\"user_001\",\n",
    "    device_id=\"device_unknown_123\",\n",
    "    ip=\"185.199.1.1\",\n",
    "    location_country=\"RU\",\n",
    "    mfa_used=False,\n",
    "    vpn_detected=True,\n",
    ")\n",
    "\n",
    "risk_result = score_execute(risk_input)\n",
    "print(\"Risk Score Tool Output:\")\n",
    "print(f\"  Score: {risk_result.risk_score:.2f}\")\n",
    "print(f\"  Level: {risk_result.risk_level}\")\n",
    "print(f\"  Factors: {risk_result.factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use quarantine tool (dry run)\n",
    "quarantine_input = QuarantineInput(\n",
    "    user_id=\"suspicious_user\",\n",
    "    reason=\"High-risk login detected from unknown device with VPN\",\n",
    "    duration_hours=24,\n",
    "    notify_user=True,\n",
    "    notify_admin=True,\n",
    ")\n",
    "\n",
    "quarantine_result = quarantine_execute(quarantine_input, dry_run=True)\n",
    "print(\"\\nQuarantine Tool Output (Dry Run):\")\n",
    "print(f\"  Action ID: {quarantine_result.action_id}\")\n",
    "print(f\"  Status: {quarantine_result.status}\")\n",
    "print(f\"  Expires: {quarantine_result.expires_at}\")\n",
    "print(f\"  Notifications: {quarantine_result.notifications_sent}\")\n",
    "print(f\"  Note: {quarantine_result.note}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Privacy Controls (PII Detection)\n",
    "\n",
    "Before sending data to LLMs, we detect and redact PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.privacy.pii_detector import PIIDetector, PrivacyMiddleware\n",
    "\n",
    "# Initialize PII detector\n",
    "detector = PIIDetector()\n",
    "\n",
    "# Test PII detection\n",
    "test_texts = [\n",
    "    \"User john.doe@example.com logged in from 192.168.1.100\",\n",
    "    \"Contact support at 555-123-4567 for help\",\n",
    "    \"SSN: 123-45-6789 found in request\",\n",
    "    \"Normal login from San Francisco at 3pm\",\n",
    "]\n",
    "\n",
    "print(\"PII Detection Results:\")\n",
    "print(\"=\" * 60)\n",
    "for text in test_texts:\n",
    "    result = detector.detect(text)\n",
    "    print(f\"\\nOriginal: {text}\")\n",
    "    print(f\"Redacted: {result.redacted_text}\")\n",
    "    print(f\"PII Found: {result.has_pii} ({len(result.entities_found)} entities)\")\n",
    "    if result.entities_found:\n",
    "        for e in result.entities_found:\n",
    "            print(f\"  - {e['type']}: '{e['text']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privacy middleware for LLM processing\n",
    "middleware = PrivacyMiddleware()\n",
    "\n",
    "processed = middleware.process_for_llm(\n",
    "    text=\"User john.doe@example.com (SSN: 123-45-6789) logged in from IP 10.0.0.1\",\n",
    "    context={\n",
    "        \"email\": \"john.doe@example.com\",\n",
    "        \"ip\": \"10.0.0.1\",\n",
    "        \"user_id\": \"user_001\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nPrivacy Middleware Output:\")\n",
    "print(f\"  Processed text: {processed['text']}\")\n",
    "print(f\"  PII detected: {processed['pii_detected']}\")\n",
    "print(f\"  Entity count: {processed['entity_count']}\")\n",
    "print(f\"  Processed context: {processed['context']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. End-to-End Demo\n",
    "\n",
    "Complete flow: event -> agent analysis -> RAG explanation -> privacy-safe output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate incoming login event\n",
    "incoming_event = {\n",
    "    \"user_id\": \"john.doe@example.com\",  # Contains PII!\n",
    "    \"device_id\": \"device_unknown_new\",\n",
    "    \"ip\": \"185.199.50.50\",\n",
    "    \"location_country\": \"RU\",\n",
    "    \"mfa_used\": False,\n",
    "    \"vpn_detected\": True,\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"END-TO-END RISK ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Run agent analysis\n",
    "print(\"\\n1. Agent Analysis:\")\n",
    "agent_result = run_risk_agent(\n",
    "    user_id=incoming_event[\"user_id\"],\n",
    "    device_id=incoming_event[\"device_id\"],\n",
    "    ip=incoming_event[\"ip\"],\n",
    "    mfa_used=incoming_event[\"mfa_used\"],\n",
    "    vpn_detected=incoming_event[\"vpn_detected\"],\n",
    ")\n",
    "print(f\"   Risk Score: {agent_result['risk_score']:.2f}\")\n",
    "print(f\"   Risk Level: {agent_result['risk_level'].upper()}\")\n",
    "print(f\"   Action: {agent_result['recommended_action']}\")\n",
    "\n",
    "# 2. Get RAG explanation\n",
    "print(\"\\n2. RAG Explanation:\")\n",
    "explanation = rag.query(\n",
    "    query=\"Why is this login suspicious?\",\n",
    "    event=incoming_event,\n",
    "    risk_score=agent_result[\"risk_score\"],\n",
    "    risk_level=agent_result[\"risk_level\"],\n",
    "    risk_factors=[\"Unknown device\", \"VPN\", \"No MFA\", \"High-risk country\"],\n",
    ")\n",
    "print(explanation[\"explanation\"][:500] + \"...\")\n",
    "\n",
    "# 3. Apply privacy controls before logging\n",
    "print(\"\\n3. Privacy-Safe Log Entry:\")\n",
    "safe_log = middleware.process_for_llm(\n",
    "    text=f\"Risk alert for {incoming_event['user_id']} from IP {incoming_event['ip']}\",\n",
    "    context=incoming_event,\n",
    ")\n",
    "print(f\"   {safe_log['text']}\")\n",
    "print(f\"   PII entities redacted: {safe_log['entity_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Phase 3 implements:\n",
    "\n",
    "1. **Vector Store** - Qdrant + sentence-transformers for semantic event search\n",
    "2. **RAG Pipeline** - Context-aware explanations combining retrieval + generation\n",
    "3. **LangGraph Agent** - Autonomous risk analysis with state machine workflow\n",
    "4. **MCP-like Tools** - Pydantic-validated tools for agent actions\n",
    "5. **Privacy Controls** - PII detection and redaction before LLM processing\n",
    "\n",
    "The agent can:\n",
    "- Analyze login events and compute risk scores\n",
    "- Investigate high-risk events by retrieving user history\n",
    "- Search for similar historical events\n",
    "- Recommend actions (block, step-up auth, monitor)\n",
    "- Generate human-readable explanations\n",
    "- Protect PII throughout the pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
